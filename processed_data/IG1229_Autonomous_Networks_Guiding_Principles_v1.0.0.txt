# Introduction

TM Forum 2020. All Rights Reserved.

# Guiding Principles for building

and measuring Autonomous

# Network Solutions

IG1229 Team Approved Date: 02-Oct-2020 Release Status: Production Approval Status: TM Forum Approved Version: 1. 0. 0 IPR Mode: RAND IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 2 of 43

# Notice

Copyright  TM Forum 2020. All Rights Reserved. This document and translations of it may be copied and furnished to others, and derivative works that comment on or otherwise explain it or assist in its implementation may be prepared, copied, published, and distributed, in whole or in part, without restriction of any kind, provided that the above copyright notice and this section are included on all such copies and derivative works. However, this document itself may not be modified in any way, including by removing the copyright notice or references to TM FORUM, except as needed for the purpose of developing any document or deliverable produced by a TM FORUM Collaboration Project Team (in which case the rules applicable to copyrights, as set forth in the TM FORUM IPR Policy, must be followed) or as required to translate it into languages other than English. The limited permissions granted above are perpetual and will not be revoked by TM FORUM or its successors or assigns. This document and the information contained herein is provided on an AS IS basis and TM FORUM DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTY THAT THE USE OF THE INFORMATION HEREIN WILL NOT INFRINGE ANY OWNERSHIP RIGHTS OR ANY IMPLIED WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. TM FORUM invites any TM FORUM Member or any other party that believes it has patent claims that would necessarily be infringed by implementations of this TM Forum Standards Final Deliverable, to notify the TM FORUM Team Administrator and provide an indication of its willingness to grant patent licenses to such patent claims in a manner consistent with the IPR Mode of the TM FORUM Collaboration Project Team that produced this deliverable. The TM FORUM invites any party to contact the TM FORUM Team Administrator if it is aware of a claim of ownership of any patent claims that would necessarily be infringed by implementations of this TM FORUM Standards Final Deliverable by a patent holder that is not willing to provide a license to such patent claims in a manner consistent with the IPR Mode of the TM FORUM Collaboration Project Team that produced this TM FORUM Standards Final Deliverable. TM FORUM may include such claims on its website but disclaims any obligation to do so. TM FORUM takes no position regarding the validity or scope of any intellectual property or other rights that might be claimed to pertain to the implementation or use of the technology described in this TM FORUM Standards Final Deliverable or the extent to which any license under such rights might or might not be available; neither does it represent that it has made any effort to identify any such rights. Information on TM FORUMs procedures with respect to rights in any document or deliverable produced by a TM FORUM Collaboration Project Team can be found on the TM FORUM website. Copies of claims of rights made available for publication and any assurances of licenses to be made available, or the result of an attempt made to obtain a general license or permission for the use of such proprietary rights by implementers or users of this TM FORUM Standards Final Deliverable, can be obtained from the TM FORUM Team Administrator. TM FORUM makes no representation that any information or list of intellectual property rights will at any time be complete, or that any claims in such list are, in fact, Essential Claims. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 3 of 43 Direct inquiries to the TM Forum office: 181 New Road, Suite 304 Parsippany, NJ 07054 USA Tel No. 1 973 944 5100 Fax No. 1 973 998 7916 TM Forum Web Page: www. tmforum. org IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 4 of 43

# Table of Contents

Notice. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 Terminology. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 1 Purpose. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2 Target Audience. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 3 Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 4 Business Drivers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 5 Business Driver Principles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 5. 1 Scope. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 5. 2 Customer Experience (CX). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 5. 3 Cost of Operation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 5. 4 Speed of Operation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 5. 5 Reliability of Operation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 5. 6 Quality of Operation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 5. 7 Flexibility of operation to make changes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 5. 8 Risk of Business Discontinuity. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 6 Observability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 6. 1 Autonomy. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 6. 2 Trust and Understandability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 6. 3 Deployability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 6. 4 Adaptability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 6. 5 Sustainability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 6. 6 Consumability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 6. 7 Resource Efficiency and Utilization. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 6. 7. 1 Resource Efficiency. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 6. 7. 2 Resource Utilization. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 6. 8 Quality of experience. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 6. 9 Observability Principles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 6. 9. 1 Observability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 6. 9. 2 AN key performance indicators. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 6. 9. 3 Traceability for audit purposes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 7 Responsibility Principles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 7. 1 Responsibilities at first startup of AN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 7. 2 Machine and human responsibility. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 7. 3 Responsibility awareness. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 7. 4 Assignment and removal of responsibility. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 5 of 43 7. 5 Responsibility handover. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27 8 Autonomy degradation and failure handling principles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 8. 1 Degradation of autonomous functionality. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 8. 2 Failure of autonomous functionality. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 9 Behavior and Explainability Principles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 9. 1 Indistinguishable behavior of AN from human operated network (analogous to a Turing test ). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 9. 2 Adjusting behavior of an AN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 9. 3 Explainable behavior. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 9. 4 Predictable behavior. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 9. 5 Uncertainty estimation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30 10 Principles of Human-Machine Interaction (HMI). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 10. 1 Human-machine interface  human-agent teaming. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 10. 2 Flight simulator mode. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 10. 3 User profiles to better optimize human: machine collaboration. . . . . . . . . . . . . . . . . . . . . . 33 10. 4 Human-machine interface presentation of information. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 10. 5 Human-machine interface multi-modality (AN  network operator domain experts). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 10. 6 Transformation of product documentation into digital knowledge assets. . . . . . 33 11 References. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 12 Administrative. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 12. 1 Document History. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 12. 1. 1 Version History. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 12. 1. 2 Release History. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 12. 2 Acknowledgments. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 12. 3 Contributions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 13 Appendix I: AN Guiding Principles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 14 Appendix II: Map of Guiding Principles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 6 of 43

# List of Figures

Figure 1 Guiding Principles (Categorized). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 Figure 2 AN Guiding Principles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 Figure 3 General economic theory: factors of production, and production model. . . . . . . . . . . . . . . . . . . . 13 Figure 4 CSP Factors of production, production model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 Figure 5 Operations typology - the 4 Vs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 Figure 6 Balance of Autonomy. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 Figure 7 Observability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 Figure 8 Autonomy: Intelligence versus Capability. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 Figure 9 Rough AN business logic state machine. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 Figure 10 Human machine collaboration activities. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Figure 11 Guiding principles detailed. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 Figure 12 Guiding Principles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 7 of 43

# List of Tables

Table 1 Complete list of Guiding Principles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 Table 2 Guiding Principles Quick Reference. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 8 of 43

# Terminology

Term Definition / Source Autonomy The capability to make decisions free from human control. Accountability Accountability requires the AI and people behind the AI explain, justify, and take responsibility for any decision and action made by the AI. Mechanisms, such as governance and tools, are necessary to achieve accountability.

# Observability

Explainability Explainability is the ability to explain how AI works (i. e. make their decisions). Explanations should be produced regarding both the procedures followed by the AI (i. e. , its inputs, methods, models, and outputs) and the specific decisions that are made. These explanations should be accessible to people with varying degrees of expertise and capabilities including the public. AI engineering discipline should be sufficiently advanced such that technical experts possess an appropriate understanding of the technology, development processes, and operational methods of its AI systems, including the ability to explain the sources and triggers for decisions through transparent, traceable processes and auditable methodologies, data sources, and design procedure and documentation. 1 SON Self-Organizing Network 1 Derived from ACM Principles for Algorithmic Transparency and Accountability https: //www. acm. org/binaries/content/assets/publicpolicy/2017_usacm_statement_algorithms. pdf IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 9 of 43 1 Purpose This document outlines a set of guiding principles to help support design, build, and measurement of an autonomous network (AN) solution. The principles are varied: some are high level to guide solutions design, whereas others address more granular issues regarding contextual, cultural, and pragmatic aspects of an implementation. The document is intended as a complement to the AN business architectureref 10 and technical reference architecture ref 11. The AN business architecture takes a top-down customer-oriented approach, whereas this document considers the broader set of business and operational drivers that will need to be considered when adopting an AN. The AN technical architecture provides a technical reference architecture on which to base a solution design, whereas this document focuses on some of the pragmatic operational aspects of a solution. Both the business architecture and technical reference architecture cover the AN levels of autonomy, whilst this document outlines observability requirements for an AN solution more broadly. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 10 of 43 2 Target Audience

# The target audience for this document is

enterprise architects and technology planners involved in planning todays and tomorrows network solutions  product managers of service, network, and operational support products sold into telco and enterprise markets  software developers and solution integrators involved in implementing network solutions and automation initiatives  operations specialists involved in running todays customer-facing and resource-facing operations teams IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 11 of 43 3 Introduction The words autonomous network (or indeed autonomous anything) prompts many questions  How will they work  What will they cost  Will humans be needed at all in the future  If there are few (or no) humans involved what happens when the Autonomous Network (or AN for short) degrade and/or fail  How will the AN know when it is failed  How do we know that the AN will be fair and equitable to all customers, partners, and users No one has definitive and detailed answers for all these and many other practical questions. What is clear, however, is that networks with level 5 autonomy are still quite a long way off. Until they exist the AN consists of teams of humans and machines collaborating to deliver and sustain services. This collaboration is very important to secure successful business outcomes and is discussed later in this document. Telecom is not the first sector to embrace autonomy, and so it is possible to learn and infer from experiences in other sectors, such as manufacturing, automotive, and shipping (see references 1-5). Research into these learnings has resulted in a set of categories of relevant guiding principles for AN, summarized by category in Appendix I, which are explored in the rest of this document. Figure 1 Guiding Principles (Categorized) The following chapters will describe the principles belonging to the categories. The numbers in the Figure 2 AN Guiding Principles corresponds to the section it is covered in. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 12 of 43 Figure 2 AN Guiding Principles IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 13 of 43 4 Business Drivers The drivers for AN will vary from CSP to CSP, but fundamentally they are not so different to the drivers of any type of commercial production operation. A CSP is also a production operation, producing connectivity and connectivity related services. Using general economic theory 4 factors of production as a basis the factors of production are depicted in Figure 3. Figure 3 General economic theory: factors of production, and production model Production processes generally make use of capital and labor to convert raw materials into finished products, and inevitably there is some amount of waste which impacts profitability. Figure 4 CSP Factors of production, production model IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 14 of 43 Applying the same logic to the CSP: the production process converts energy into ICT services, using network and IT infrastructure and the people who operate them, as depicted in Figure 4. If all of the engineered network capacity is not used, then there is also waste. These simplified production models essentially set out the main levers that an organization has to change business outcomes. They can expand their channels to market via various ecosystems, which should reduce unused capacity, but this requires the production model to transform. Many companies in manufacturing industries have already transformed by adopting technologies (e. g. industrial robots) and created highly automated flexible manufacturing engines. ANs can transform the CSP production model in the same way, increasing resource utilization and energy efficiency, and creating network services tailored to customer needs. Although all operations processes are similar in that they all transform inputs, they do differ in a number of ways, four of which, known as the four Vs according to ref6, are particularly important: the volume of their output  the variety of their output  the variation in the demand for their output  the degree of visibility which customers have of the creation of their output. All four dimensions have implications for the cost of creating and delivering services and products. Put simply: high volume, low variety, low variation, and low customer contact all help to keep processing costs down. Conversely, low volume, high variety, high variation, and high customer contact will generally carry a cost penalty for the operation. This is best illustrated with the operations typology chart used in ref 6, as depicted in Figure 5. Figure 5 Operations typology - the 4 Vs IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 15 of 43 Different CSPs will have varying ambitions on each of these Vs according to their business strategy, all with their own trade-offs. The AN must allow a CSP achieve the appropriate level of V for each market segment, or even partner or customer (if required). Analyzing any of the main public cloud service providers through these V prisms its evident they have designed their platform and products to: be very high volume if required, and, critically, without a corresponding increase in cost  provide a reasonable (but not infinite) amount of variety  provide great ability to handle variations in demand (scale up, scale down)  provide acceptable visibility through the use of APIs and intelligent agents(bots) These are good baseline targets for a CSP also. An operation contributes to business strategy by achieving the following performance objectives: 1. Doing things right, resulting in a quality advantage 2. Doing things fast, resulting in a speed advantage 3. Doing things on time, resulting in a reliability (or dependability) advantage 4. Changing the things that are done, resulting in a flexibility advantage 5. Doing things cheaply, resulting in a cost advantage 6. Focusing on the customer, resulting in reputation and brand advantages that enable pricing power versus the competition 7. Keep doing things in times of adversity, resulting in a business continuity advantage The commercial success of AN should be judged using all of these objectives, and thus they should underpin the principles used when designing and implementing an AN solution. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 16 of 43 5 Business Driver Principles Every CSP is different, and so are their precise business drivers. Thus principles 1-7 below will apply in different amounts to each customer. As described in ref 10 and ref11 these are expressed with intent, at customer, partner, business, and service and network operational layers, and the role of the AN will be to reconcile and resolve the conflicts, both initially and on an ongoing basis. 5. 1 Scope Everything within the AN shall not need to be fully (or even partially) autonomous, it may not be justified from a business perspective. This is an overarching principle to remind us that its extremely unlikely (or even infeasible) that every single part of the CSP business will be fully autonomous. In fact, in some cases, too much autonomous behavior may be counterproductive, and create more issues than it resolves. Per ref7 the performance of the human-machine system increases with the autonomy of the machine, but only until some optimum, after which it decreases. That is because if the autonomy of the machine is further increased, the human operator is likely to lose control of the situation, and performance then regresses, as shown in Figure 6 below. Figure 6 Balance of Autonomy Furthermore, excessive automation tends to lower the level of vigilance of human operators of highly automated systems, that is: the more intelligent a system is the more complacent the IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 17 of 43 human operator becomes - this can also be counterproductive. Thus: not every function should reach L5 autonomy. This could be revisited when industry efforts have realized systems that are getting close to L5 autonomy, this is not in the near term, however. 5. 2 Customer Experience (CX) Customer experience shall, for most CSPs, be a key driving factor when considering and deciding how autonomous a function or domain should be. The focus shall be on how customer is going to experience the product (or service) provided by the network and what happens if and when it fails or degrades. 5. 3 Cost of Operation Cost of sustainment (or cost to operate) shall drive the need to implement autonomous behavior. Generally, functions that are more costly and onerous to operate should be prioritized over ones that are less costly. The AN shall help the CSP deliver products and services at lower per unit costs, maximize the utilization of their assets, and minimize waste. 5. 4 Speed of Operation Speed of operation shall drive the need to implement autonomous behavior. Functions that are slow, or that regularly become bottlenecks, are obvious candidates to target for some (or full) autonomy. The AN shall help the CSP reduce execution times across all tasks and disciplines: service design and creation, network rollout, service, network, and customer provisioning, assurance, billing, rating, migrations, service retirement, etc. 5. 5 Reliability of Operation Reliability (or dependability) shall drive the need to implement autonomous behavior. Reliability means doing things in time so that customers receive the right set of products and services exactly when they are needed, or at least when they were promised. Over the long term being reliable translates into time and cost savings, improving the business reputation, and ultimately increasing future revenue potential. The AN shall help the CSP become more reliable. 5. 6 Quality of Operation Quality is consistent conformance to customers (and partners and regulators) expectations - in other words doing things right. Doing things right shall drive the need for autonomous behavior. In some ways quality is the most visible part of what a CSP does from a customer perspective, and thus is related to guiding principle 1 because its often perceived(especially bad experience), but quality is about more than customer experience. The AN shall help the CSP deliver error-free products and services which are fit for purpose. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 18 of 43 5. 7 Flexibility of operation to make changes Flexibility of operation shall drive the need to implement autonomous behavior. Today customers demand greater flexibility in the following ways: product/service flexibility  ability to introduce new or modified products and services  product/service mix flexibility  ability to produce a wide range or mix of products and services  volume flexibility  ability to change level of output or activity to support different product volumes, or capacities  delivery flexibility  ability to change the timing of delivery of services and products. The AN shall help the CSP become more flexible to customers changing needs. 5. 8 Risk of Business Discontinuity Risk of business discontinuity shall drive the need to implement autonomous behavior. Business discontinuity can happen for several reasons; examples would be IT security attacks, or organizational competence gaps (e. g. due to CSP staff aging demography, or faster pace of technological change). The AN shall enable the CSP to have more robust business continuity plans and procedures. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 19 of 43 6 Observability To see what is going on inside a system under observation, the system must be observable. That is: there must be measures, or metrics, produced by the system that can be monitored externally. Autonomy will be the metric used to translate to the autonomous levels mentioned in the business architectureref 10 and technical ref architectureref 11. If, for example, a network domains autonomy is 100 (i. e. all activities are performed by a machine and no activities are performed by humans) then this would translate to autonomous level 5. While the autonomous level is informative about the system capability in terms of autonomous behavior it is not the only measure needed to ensure a successful business outcome when using an AN. In general, as a system gets more autonomous more (not less) observability data is needed to assure that everything is working correctly, and to better effect than traditional more manual methods. 3GPP observability focus has been on specific network performance indicators which, in most cases, were observed by humans. As autonomy levels increase machines will do more of these observations, and take more decisions that, ordinarily, are taken by humans today. Thus: these automated processes and the logic that drives them need to be more observable. A candidate set of observability categories are outlined below. Note that these are not fully elaborated metrics and formulae. Figure 7 Observability 6. 1 Autonomy The autonomy of a system is measure of its ability to make choices and enforce its decisions. To have autonomy (or act autonomously) the system must have (1) intelligence and (2) capability, and these are both bounded, as shown in Figure 8. There is little or no value in building an extremely intelligent system that can make many choices independently if the system does not have the capability to implement the choices. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 20 of 43 Figure 8 Autonomy: Intelligence versus Capability To use a simple example: take the case of a robotic lawnmower. These are excellent intelligent products for flat and undulating terrain, but their capability often limits their autonomy, and therefore utility. For gardens that are split level, or non-contiguous, for example, the robotic lawnmower does not have the capability to autonomously move between one area and another - a human must intervene. The lawnmowers autonomy is therefore bounded by its capability. Thus: system autonomy is best measured as a function of what tasks and operations can be done independently, and what requires human intervention. At a very simplistic level it would be expressed as follows: 𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂 𝑂𝑂ℎ𝑂𝑂𝑂𝑂 𝑑𝑑𝑂𝑂𝑂𝑂𝑂𝑂 𝑂𝑂𝑂𝑂𝑟𝑟𝑟𝑟𝑂𝑂𝑂𝑂𝑂𝑂 ℎ𝑟𝑟𝑢𝑢𝑂𝑂𝑂𝑂 𝑂𝑂𝑂𝑂𝑖𝑖𝑂𝑂𝑖𝑖𝑖𝑖𝑂𝑂𝑢𝑢𝑂𝑂𝑂𝑂𝑂𝑂  𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂𝑂 To enable calculation of such a metric telemetry data is required   operations (or tasks undertaken)   operations that require human involvement   operations that do not require human involvement These should be available over many dimensions of analysis, such as: time of day, day of week, user ID, domain, operation type, object type, attributes, object instance, vendor, software version. When SON (self-organizing networks) were introduced by 3GPP in 2010 (and appeared in commercial products subsequently) all configuration changes made by the network were logged alongside human-applied configuration changes, thus it was, in theory, possible to compute what  of configuration changes were made. A similar (but broader) set of telemetry will be needed to measure broader network autonomy. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 21 of 43 6. 2 Trust and Understandability For humans to delegate many of their business and network operation responsibilities to a machine they must trust the machine will deliver an equivalent (or even better) business outcome. Without that trust adoption of the AN will be a significant challenge. Trust depends on mutual understanding, that is: a human must first understand the behavior of the AN before they can grow to trust it. The behavior and competence exhibited used by the AN must be appreciated by humans for it to engender trust, and this must be consistent over time. At a high level, trust can be simply defined as follows: 𝑇𝑇𝑂𝑂𝑟𝑟𝑂𝑂𝑂𝑂  𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶𝐶 𝑇𝑇𝐶𝐶𝑇𝑇𝐶𝐶 More practically there are three dimensions to trust that must be considered: Dependability: the belief that the system will do what it indicates it will do (or what business policies indicate it should do). This largely pertains to metrics that already exist for service availability, reliability, and integrity, but would also include safety (no bad consequences for users or the environment), encompassing confidentiality and security. Competence: the belief that the system has the ability to do what it indicates it will do (or what business policies indicate it should do). It can be assessed by tracking how often (or not) a human agrees with what the AN is suggesting as a course of action. Each recommended course of action should come with an explanation. Satisfaction with the explanation can be measured by collecting human feedback from the user interface. Integrity: the belief that a system is fair and just. This relates to bias, and whether the system exhibits any form of bias towards customers, customer groups, partners, etc. This bias could be explicit (attitudes or beliefs expressed at a conscious level of awareness) or implicit. Human curiosity is also something that should be considered. That is: how do users interact with explanations. This can inform us on the quality of the explanations the system is providing, and whether the mental models used within the explanations are appropriate for users.

# Ideally it should be possible to track

suggestions made by AN   user feedbacks provided on suggested made by AN (satisfactory and unsatisfactory)   operations whose underlying logic and output can be accounted for   operations of whose underlying logic and output can be accounted for At a deeper technical level where AI is used AI model inputs and outputs should be tracked to identity irregularities which may indicate bias within an algorithm. 6. 3 Deployability Deployability is a measure of how straightforward a system is to deploy. This could be measured in terms of deployment time (i. e. how long does it take) deployment success rate (i. e. is the deployment 100 successful, or does a human have to intervene to resolve some issues). Naturally when the network is autonomous these metrics should be (1) better than todays more traditional deployment approaches and (2) continuously improving. The following types of data would, at a minimum, be required from telemetry: -  Total time to deploy  Time deployment process had to be paused IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 22 of 43   associated work orders   humans involved   human operations involved 6. 4 Adaptability Adaptability is a measure of how good a system is at adapting to state changes, whether caused internally, or via the external environment. Whenever major changes occur the AN will, for some amount of time, go into a state of inequilibrium, where it is no longer synchronized with the network. The goal is to return to a state of equilibrium as quickly as possible in order to remain in control. Measurements that matter are  Time in in-equilibrium: time in which the AN is adjusting to dynamic changes, and therefore is not in complete control  Time to adapt: time taken for the AN to adjust to the above mentioned changes (e. g. ML models are retrained etc. ). In control theory this is called time to reach accuracy  Time between adaptations: time between two adaptations, indicating how robustly the autonomous system (or function) is handling incoming network data. This is akin to a term within machine learning, called performance drift. Drift is about monitoring model KPIs to determine model performance, which may trigger a retraining process if drift has occurred. If incoming network data is dramatically different to the training data which the model has been created, then performance drift often will occur. 6. 5 Sustainability CSPs are significant users of energy and markets generally expect them to report on their usage and how they are reducing their carbon footprint. The AN should help the operator monitor and actively reduce the power consumption and therefore CO2 emissions. The following types of KPIs are relevant: Energy Consumption  Energy Consumption by source (Fossil fuel, nuclear, solar, wind, EV battery)  Carbon Footprint (ktons of CO2)  Water consumption (for cooling systems, where applicable) As examples two publicly quoted objectives from Telia and BT, per their annual reports: -  Telia: be Co2 neutral and zero waste by 2030  BT: reduce Co2 emissions by 87 by 2030 6. 6 Consumability One of the main customer criticisms of CSPs today is that they cannot deliver services quickly and frictionlessly like cloud service providers. In contrast products and services offered by cloud service providers are very consumable: customers can easily select what they need, configure it, and it is available for use instantly, or, in the worst case, a few minutes later. With cloud: services have been transformed into the equivalent of utilities. They can be IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 23 of 43 turned on when you need them, and off when you do not. This is where CSPs need to get to.

# Key consumability metrics for a CSP will be

Time to find product  Time to order  Time to service consumption  Time to customize service  Time to modify service (e. g. increase or reduce capacity, add more branch offices, etc. )  Time to cancel  Number of human interventions required, per transaction (this should be zero, or close to zero, per cloud service providers) 6. 7 Resource Efficiency and Utilization These metrics are not new for ANs but are very important comparatively. An AN should do much better here than a manually operated network, otherwise the business case for AN is not as strong. 6. 7. 1 Resource Efficiency Many operators talk about production cost or production cost-per-bit. The more resource efficient the network the lower the production cost. CSP will want to track how good the AN is at achieving efficiency gains versus a manually operated network. The AN should be able to do more with less, e. g. if 100 CPUs costing 100K/month are needed to improve a process costing 90K/month by 15 that is not a good result

# Metrics such as the following are relevant

CPU unit / MB consumed  Memory unit / MB consumed  kWH / MB consumed  human minutes expended / MB consumed 6. 7. 2 Resource Utilization This is about understanding how good the AN is at achieving better resource utilization levels. The metrics will focus on resource utilization across CPU, memory, radio frequency. 6. 8 Quality of experience Similar to resource efficiency and utilizations QoE metrics are not new. The AN should deliver better customer perceived quality of experience (QoE) to all applications that use it, and it should be comparably better than a network that is manually operated. This QoE should cover the full lifecycle, using SLAs where required, covering  Time to order IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 24 of 43  Time to set up  Service outage time  Time to modify  Time to repair (in the event of a service outage)  Standard technical QoS metrics associated with the applications o Accessibility and access latency o Retainability o Throughput o Packet loss o Latency  Achieved QoS Rate: QoS is negotiated, customers often get less than they request today. This phenomenon should reduce with the AN based on better resource allocation policies 6. 9 Observability Principles 6. 9. 1 Observability All components within an AN shall be observable. All domains (and functions within domains) shall produce appropriate data to support SLA monitoring  automated incident detection and alerting  analysis of system health (historical trends and analytics)  manual debugging - when necessary  Appropriate data includes Metrics (standardized and non-standardized performance counters), KPIs (useful for analytics), Logs (useful for behavioral understanding and problem determination purposes), Health check outputs (useful to understand health status of individual components), Tracing (useful for understanding control flow from one domain (or function) to another). Given that an AN is a heterogeneous environment interoperability in this area is important. 6. 9. 2 AN key performance indicators New dimensions of analysis shall be necessary to measure and evaluate the success of ANs. New KPIs shall be specified as part of standardization efforts but nominally the output shall consist of the following KPI categories: autonomy, consumability, trust, sustainability, adaptability and deployability. Many existing KPIs will not change however it is expected AN should improve KPI values over time. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 25 of 43 6. 9. 3 Traceability for audit purposes The AN shall record all relevant data pertaining to the status of the network and its components, and what events and incidents trigger it to act. This trace shall include references to the responsibility matrix, e. g. 24/8/2020: user JamesOS approved ADN recommended action B to reset base station DublinRBS001A These traces shall be archived for auditing purposes. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 26 of 43 7 Responsibility Principles As with other sectors the subject of responsibility is an important one for autonomous systems. There are often gray areas in this area that cause lots of controversy. Simplistically: for an L0 AN system the human carries out all activities and therefore is 100 responsible. for an L5 AN system the network (or machine) carries out all activities and therefore is 100 responsible. Idealistic perhaps, but mathematically correct  Most networks are somewhere between 0 and 5 and thus responsibility is shared. The challenge is the percentage of sharing in L1-L4 networks can be very dynamic, and it can be very difficult to track. The following principles are outlined to help with the creation of CSP specific situational awareness mechanisms. 7. 1 Responsibilities at first startup of AN Upon the first startup of the AN autonomous functionality shall be enabled, but not activated2. In fact: it will be running in background to learn from human 7. 2 Machine and human responsibility Over time the AN shall independently improve consumability, performance, and efficiency in most common situations however human intervention can be expected to be required for knowledge augmentation, judgement, decision making and execution, especially in corner or edge cases Humans shall also perform ongoing monitoring, validation, and audit of the behavior of the AN and its constituent parts (domains) 7. 3 Responsibility awareness The functions and tasks that remain under direct human responsibility must be clear to them at all times. The functions and tasks that are delegated to the AN must be evident to the relevant human(s) at all times, as well as when the status changes. A dynamic responsibility matrix shall exist for each AN domain and function within a domain (e. g. PASCI or RACI - see definitions ) 2 This is a principle adopted by self-organizing networks (SON) when those capabilities were introduced in LTE. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 27 of 43 7. 4 Assignment and removal of responsibility  A suitably authorized human can delegate and remove task responsibilities from the AN at any stage. Delegation of tasks may fail (e. g. if the AN is not ready from a state management perspective). Removal of responsibility shall not fail in general. However, to ensure the system remains in a consistent and safe state, some transactions may be completed by the machine before it can release responsibility. 7. 5 Responsibility handover In the event the AN detects that it needs to hand over some or all overtake responsibility to a human  the handover reason(s) shall be clear  the AN shall request a confirmation that the human has accepted the handover  if no confirmation is forthcoming the AN shall take steps to secure a safe steady state (there may be some negative consequences), these steps would essentially be heuristics and predetermined rules that are appropriate to the specific scenario. In parallel use a defined communication escalation path to inform appropriate staff that the handover has taken place IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 28 of 43 8 Autonomy degradation and failure handling principles If a function or system is autonomous the impact to business outcomes as a consequence of a degradation and failure need to be extremely clear to all involved. In fact: some functions may not be automatable at all if conditions around stability are too difficult to achieve during degraded or failure conditions. The following state machine depicts the general business logic that is needed to ensure stability. Figure 9 Rough AN business logic state machine 8. 1 Degradation of autonomous functionality In the situation where autonomous functionality degrades the AN shall be aware of the degradation, and report it, but shall still be capable of running the function at reduced capacity/availability/etc. levels whilst the degradation is triaged with the help of a human. 8. 2 Failure of autonomous functionality In the situation the autonomous functionality fails, the AN shall be aware of the failure, and control shall be reverted to a human. Procedures to revert the system or functionality to a consistent known state shall exist and be understood by all. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 29 of 43 9 Behavior and Explainability Principles 9. 1 Indistinguishable behavior of AN from human operated network (analogous to a Turing test 3) The AN shall exhibit behaviors that are consistent with manually operated networks so that all participants within an ecosystem can continue to seamlessly interoperate, as before.

# Participants include

Mobile terminals (i. e. UEs)  Roaming partners  Internet exchanges  Interconnection exchanges  Cloud service providers  Vertical industries The full or partial introduction of an AN shall be fully transparent to ecosystem participants. 9. 2 Adjusting behavior of an AN Where inappropriate or incorrect AN behavior is detected the human shall have the ability to teach and help the network to adjust its behavior. The effect of the adjustment shall typically be gradual. 9. 3 Explainable behavior The behavior of the AN shall be easy-to-understand for competent humans The AN shall be able to explain its behavior and decision making to competent humans in terms that they understand 9. 4 Predictable behavior Given the same starting state and set of input events the AN running a given set of software versions shall always produce the same result. 3 Note 1: when ANs communicate to other ANs its highly likely the dialog can be more optimized once the initial preamble exchange takes place. Note 2: this is not intended to be an official Turing test as not all autonomous functions will be implemented using AI IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 30 of 43 9. 5 Uncertainty estimation The AN should use uncertainty estimation throughout to ensure only high confidence actions are executed autonomously. The setting for high confidence would typically be set as a policy by a human and would vary per use case and scenario. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 31 of 43 10 Principles of Human-Machine Interaction (HMI) Human-machine interaction (HMI) is a crucial element for the safe and stable operation of ANs. As it progresses up the autonomous levels the AN takes on more tasks and the human does less, being freed up to do more strategic work within the business. This often gives rise to the so-called control problem ref 12, 13, which is the tendency of the human agent within a humanmachine control loop to become complacent, over-reliant or unduly diffident when faced with the outputs of a reliable autonomous system. To paraphrase it in logic: The control problem occurs when: Machine automation fails OR degrades to a level that is problematic

# AND

Human does not notice OR is incapable of taking over responsibility when needed  Note that this problem is not unique to AI or ML powered automation, it applies to any type of automation implementation. If AN is 100 reliable in terms of delivering business outcomes then human supervision is not necessary, and thus the control problem will not occur. The reality, however, is that very few automation functions are 100 reliable so some human supervision is still needed. Almost 100 reliability is actually the biggest issue: - Extremely high (but not 100) reliability engenders complacency in humans, and they often switch off, which means they are not ready to take over if the machine automation encounters an insurmountable problem - because the automation is so reliable humans do not get to practice many of the normal day-to-day tasks that they performed in the past, thus they slowly become deskilled. The most important goal for the AN HMI is to secure the users correct interpretation of the network status, and that they understand their responsibilities in the moment of a responsibility transition. Based on research in other fields (military, aviation, shipping) ref 13 the appropriate and practical ways to alleviate the control problem are - Ensure the human still has a meaningful and active role in policing the automation. This may counter-intuitively mean using less reliable technical solutions in some instances to instill greater vigilance in humans. The targeted scenarios may vary per operator, a needs analysis is needed as part of AN solution planning. - Introduce simulated accountability measures (so called catch trials) in which system errors are deliberately generated to keep human invigilators situationally aware. This could be quite useful in counteracting automation bias and has been quite successful in the autonomous shipping industry. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 32 of 43 On the first alleviation point a pragmatic role partitioning and collaboration strategy is required for each CSP. The general methodology put forward by Accenture principals in ref 8 may be a good starting point. Figure 10 is a slightly adjusted version adopted from the book, where the central six roles are where true collaboration between humans and machines take place. Figure 10 Human machine collaboration activities Train, explain, and maintain are distinct roles that are relevant when dealing with AI or non-AI based automation. The human only and machine only designations are based on who is better and more naturally suited to these items (at least currently  machines may advance in other areas in future). In summary the AN HMI should be carefully designed to consider the psychological and cognitive traits and states of humans with the goal of optimizing the humans understanding of the current task/situation and of reducing incorrect system operation. It will not be one-size- fits-all, rather it will be self-adjusting to each CSP environment. Some related principles are outlined below: 10. 1 Human-machine interface  human-agent teaming The AN HMI shall support flexible modes of human-agent teaming, whereby a human (or group of humans) and the network behave as equal partners on a team (but human intervention is still in place, obviously), and collaborate on goals where there is shared situation awareness within the team. Shared situation awareness is knowledge about the current state of the task environment, as well as team activities, team performance, dependencies, and overall progression with respect to the team task. Such knowledge shall facilitate coordination and reallocation of tasks within the team but shall also be used for effective and efficient communication inside and outside the team members. 10. 2 Flight simulator mode As the ANs gets increasingly automated there will be less work for the user to do (in terms of traditional tasks at least). On a similar vein some parts of the network are increasingly reliable, and many error scenarios are not seen regularly, if ever (i. e. extremely rare). The result of these situations is that humans could become deskilled over time because they are not actively doing the work as they did in the past. The AN should support flight simulator style drills in a sandbox or simulation environment to help them maintain their skills and prepare for chaos monkey scenarios that, generally speaking, would not normally be experienced. This also helps address the control problem associated with all automated systems. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 33 of 43 10. 3 User profiles to better optimize human: machine collaboration To account for the fact that, just like the network, humans change over time (skills, abilities, connections, etc. ) and better enable human collaboration the AN should build targeted profiles or annotations of users to understand their technical and operational competences, abilities, and strengths, and their workplace related social network. Such profiles are useful for task/work allocation, ad hoc team formation, user behavioral analysis (to build strong machine learning models, for example), and bias detection. 10. 4 Human-machine interface presentation of information To eventually reach level 4 and 5 autonomous levels the HMI of the AN should generally only display information for which a human consultation (or decision) is necessary. Presentation of unnecessary information for the task at hand should be avoided as much as possible to avoid high cognitive load on the human which ultimately negatively impacts decision making. Note: this may not be achievable from the outset, but it should be a goal, and there should be a plan on how to achieve it 10. 5 Human-machine interface multi-modality (AN  network operator domain experts) To cater for increased customer diversity and the ongoing trend in application mobilization the AN HMI shall cater for different usage and modes of interaction. The traditional telco big screen model of network operations is not a suitable HMI for many enterprises, and majority of CSPs are mobilizing many of their systems. Where it makes practical sense and improves human-machine collaboration mobile and AI assistants shall be available for some applications and use cases. Removal of human bottlenecks

# Background: In today’s network operations many things do not happen because humans fail to

do them, due to other work, absence, or some other reason. For example: the organizations priorities were incorrect because John was out sick this morning - he did not login and run the Wireless status report. All human bottleneck tasks should be found and delegated to the ANs, and the workflow/process redesigned to ensure human bottlenecks are entirely removed. Vendor product offerings should be evaluated on how many (or few) human bottlenecks their products introduce. 10. 6 Transformation of product documentation into digital knowledge assets Humans shall not need to refer to individual product documentation for daily network operations, the AN should inform them what they need to know in any given context Product documentation concerning features, capabilities, and dependencies shall be manifested as machine readable artifacts for use by the autonomous, which shall actively use them as knowledge assets. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 34 of 43 Documentation concerning differences between network function product versions (software and hardware) shall be manifested as machine readable artifacts in order for use by the AN to actively use these facts as knowledge assets, removing painstaking and error prone investigation tasks from humans. Note: some traditional network node product documentation shall still have a role for network planners and technical staff involved in procurement evaluation processes. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 35 of 43 11 References 1. Autonomous Guided Vehicles, Methods and Model for Optimal Path Planning (2015), Fazlollahtabar, Hamed, Saidi-Mehrabad, Mohammad Link 2. Autonomous Driving, Technical, Legal and Social Aspects (2015), Markus Maurer, J. Christian Gerdes, Barbara Lenz, Hermann Winner Link 3. Towards the Autonomous Ship: Operational, Regulatory, Quality Challenges (2018),

# Aristotelis Komianos

4. Guidelines for autonomous shipping(2017), Bureau Veritas, Link 5. The human element and autonomous ships (2016), S. Ahvenjärvi, International Journal on Marine Navigation and Safety of Sea Transportation, link 6. Operations Management(2016), Slack, Branson-Jones  Johnson, link 7. Intelligent Assistant Systems: Support for Integrated Human-Machine Systems (1994), Guber, Boy, link 8. Human  Machine: Reimagining Work in the Age of AI, Daugherty  Wilson (2018), link 9. ANs: Empowering Digital Transformation for the Telecoms Industry, TMForum white paper (2019), link 10. IG1218 AN Business Requirements and Architecture v1. 0, TMForum, link 11. GB1020 An Architectural Blueprint for ANs, v1. 0, TMForum, link 12. Algorithmic decision-making and the control problem, Minds and Machines, Zerelli, Knott, Maclaurin  Gavaghan (2019) 13. Monitoring an automated system for a single failure: Vigilance and task complexity effects, Human Factors, Molloy  Parasuraman (1996) IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 36 of 43 12 Administrative 12. 1 Document History 12. 1. 1 Version History

# Number

Date Modified Modified by: Description of changes 0. 1 09-Jul-2020 James OSullivan Initial Version (Confluence) 0. 2 10-Aug-2020 Kevin McDonnell Converted to a formal GB template 0. 3 25-Aug-2020 James OSullivan Updated, reoriented some content to reflect change from a section to an independent document. Made available on TMF confluence page. 0. 4 26-Aug-2020 James OSullivan Improved HMI section. 0. 5 27-Aug-2020 James OSullivan Incorporating Kevin comments 0. 6 27-Aug-2020 Kevin McDonnell Updates to Diagrams and Appendixes 0. 7 31-Aug-2020 James OSullivan Accepting many of edits. Split production factors diagram in two  too small previously. 1. 0. 0 02-Oct-2020 Alan Pope Final edits prior to publication in 2020 Sprint 5 12. 1. 2 Release History Release Status Date Modified Modified by: Description of changes Pre-production 02-Oct-2020 Alan Pope Initial Release Production 24-Nov-2020 Adrienne Walcott Updated to reflect TM Forum

# Approved Status

12. 2 Acknowledgments This document was prepared by the members of the TM Forum ANs project: James OSullivan (Author, Huawei)  Kevin McDonnell (Contributor, Huawei)  Azahar Machwe (Contributor, BT)  Dave Milham (Contributor, TM Forum) IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 37 of 43 12. 3 Contributions

# Summary Reporter Key

Integrated Human: Machine system for AN James OSullivan ANP-79 Investment and wealth management industries - learnings for ANing James OSullivan ANP-78 AN demo mockup to illustrate some of the collaborative principles the AN needs to support James OSullivan ANP-61 Input for business/technical guiding principles James OSullivan ANP-59 Observability: measuring the AN James OSullivan ANP-47

# Systems

Azahar Machwe ANP-74 AN Guiding Principles - diagrams Kevin McDonnell ANP-110 IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 38 of 43 13 Appendix I: AN Guiding Principles The following table provides a short tabular view of the complete list of guiding principles. Table 1 Complete list of Guiding Principles. Category Principle 0 Business driver Scope Everything within the AN shall not need to be fully (or even partially) autonomous, it may not be justified from a business perspective. This is an overarching principle to remind us that it is extremely unlikely (or even infeasibly) that, pragmatically, every single part of the CSP business will not be fully autonomous. In fact, in some cases, too much autonomous may be counterproductive, and create more issues than it resolves. Per ref 7 the performance of the human-machine system increases with the autonomy of the machine, but only until some optimum, after which it decreases. That is because if the autonomy of the machine is further increased, the human operator is likely to lose control of the situation, and things then regress, as shown on below. The following will differ in priority for each CSP depending on the type, size, and goals of the business 1 Business driver Customer experience Customer experience shall, for most CSPs, be a driving factor when considering and deciding how autonomous a function or domain should be. The focus shall be on how customer is going to experience the product (or service) provided by the network and what happens if it fails or degrades. Focusing on these scenarios shall drive out the right autonomous behaviors. 2 Business driver Cost of operation Cost of sustainment (or cost to operate) shall drive the need to implement autonomous behavior. Generally, functions that are more costly and onerous to operate should be prioritized over ones that are less costly. The AN shall help the CSP deliver products and services at lower per unit costs, maximize the utilization of their assets, and minimize waste. 3 Business driver Speed of operation Speed of operation shall drive the need to implement autonomous behavior. Functions that are slow, or that regularly become bottlenecks, are obvious candidates to target for some (or full) autonomy. The AN shall help the CSP reduce execution times across all tasks and disciplines: service design and creation, network rollout, service, network, and customer provisioning, assurance, billing, rating, migrations, service retirement, etc. 4 Business driver Reliability of operation Reliability (or dependability) shall drive the need to implement autonomous behavior. Reliability means doing things in time so that customers to receive the right set of products and services exactly when they are needed, or at least when they were promised. Over the long term being reliable translates into time and cost savings, improving the business reputation, and ultimately increasing future revenue potential. The AN shall help the CSP become more reliable. 5 Business driver Quality of operation Quality is consistent conformance to customers (and partners and regulators) expectations - in other words doing things right, doing things right shall drive the need for autonomous behavior. In some ways, quality is the most visible part of what a CSP does from a customer perspective, and thus is related to guiding principle 1, but quality is about more than customer experience. The AN shall help the CSP deliver error-free products and services which are fit for purpose. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 39 of 43  Category Principle 6 Business driver Flexibility of operation to make changes Flexibility of operation shall drive the need to implement autonomous behavior. Today customers demand greater flexibility in the following ways: product/service flexibility  ability to introduce new or modified products and services  product/service mix flexibility  ability to produce a wide range or mix of products and services  volume flexibility  ability to change level of output or activity to support different product volumes, or capacities  delivery flexibility  ability to change the timing of delivery of services and products. The AN shall help the CSP become more flexible to customers changing needs. 7 Business driver Risk of business discontinuity Risk of business discontinuity shall drive the need to implement autonomous behavior. Business discontinuity can happen for several reasons; examples would be IT security attacks, or organizational competence gaps (e. g. due to CSP staff aging demography, or faster pace of technological change). The AN shall enable the CSP to have more robust business continuity plans and procedures. 8 Observability Observability The AN shall be observable. All domains (and functions within domains) shall produce appropriate data to support  automated incident detection and alerting  analysis of system health (historical trends and analytics)  manual debugging - when necessary Appropriate data includes  Metrics (standardized and non-standardized performance counters, KPIs - useful for analytics)  Logs (useful for behavioral understanding and problem determination purposes)  Health check outputs (useful to understand health status of individual components)  Tracing(useful for understanding control flow from one domain (or function) to another) Given that an AN shall be a heterogeneous environment interoperability in this area shall be important 9 Observability AN key performance indicators New dimensions of analysis shall be necessary to measure and evaluate the success of ANs. New KPIs shall be specified as part of standardization efforts but nominally the output shall consist of the following KPI categories: autonomy, consumability, trust, sustainability, adaptability and deployability. 10 Observability Traceability for audit purposes The AN shall record all relevant data pertaining to the status of the network and its components, and what events and incidents trigger it to act. This trace shall include references to the responsibility matrix (e. g. user JamesOS approved ADN recommended action B to reset base station DublinRBS001A) These traces shall be archived for auditing purposes. 11 Responsibility Responsibilities at first startup of AN Upon the first startup of the AN autonomous functionality shall be enabled, IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 40 of 43  Category Principle but not responsible. In fact: it will be running in background to learn from human  This is a principle adopted by self-organizing networks (SON) within wireless networks today. 12 Responsibility Machine and human responsibility Over time the AN shall independently improve consumability, performance, and efficiency in most common situations however human intervention shall still be required for  knowledge augmentation, judgement, decision making and execution, especially in corner or edge cases  monitoring, validating, and auditing the behavior of the AN and its constituent parts (domains) 13 Responsibility Responsibility awareness The functions and tasks that remain under human responsibility must be clear to them at all times. The functions that are under the responsibility of the autonomous must be evident to the relevant human(s) at all times, as well as when the status changes. A responsibility matrix shall exist for each AN domain and function within a domain (e. g. PASCI or RACI - see definitions ) 14 Responsibility Assignment and removal of responsibility  A suitably authorized human can assign and remove responsibilities from the AN at any stage. Assignment of responsibility may fail (e. g. if the AN is not ready from a state management perspective). Removal of responsibility shall not fail in general. However, to ensure the system remains in a consistent and safe state, some transactions may be completed by the machine before it can release responsibility. 15 Responsibility Responsibility handover In the event the AN detects that it needs to hand over some or all over responsibility to a human  the handover reason(s) shall be clear  the AN shall request a confirmation that the human has accepted the handover  if no confirmation is forthcoming the AN shall take steps to secure a safe steady state (there may be some negative consequences), and in parallel use a defined communication escalation path to inform appropriate staff that the handover has taken place 16 Degradation and failure

# Degradation of autonomous functionality

In the situation where autonomous functionality degrades the AN shall be aware of the degradation, and report it, but shall still be capable of running the function at reduced capacity/availability/etc. levels whilst the degradation is triaged with the help of a human. 17 Degradation and failure

# Failure of autonomous functionality

In the situation the autonomous functionality fails, the AN shall be aware of the failure, and control shall be reverted to a human. Procedures to revert the system or functionality to a consistent known state shall exist and be understood by all. 18 Behavior and explainability Indistinguishable behavior of an AN (like Turing test) The AN shall exhibit behaviors that are consistent with manually operated networks so that all participants within an ecosystem can continue to seamlessly interoperate, as before. Participants include  Mobile terminals (i. e. UEs)  Roaming partners  Internet exchanges  Interconnection exchanges IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 41 of 43  Category Principle  Cloud service providers  Vertical industries The introduction of an AN shall be fully transparent to ecosystem participants 19 Behavior and explainability

# Adjusting behavior of an AN

Where inappropriate or incorrect AN behavior is detected the human shall have the ability to teach and help the network to adjust its behavior. The effect of the adjustment shall typically be gradual. 20 Behavior and explainability

# Explainable behavior

The behavior of the AN shall be easy-to-understand for competent humans The AN shall be able to explain its behavior and decision making to competent humans in terms that they understand 21 Behavior and explainability

# Predictable behavior

Given the same starting state and set of input events the AN shall always produce the same result 22 Human machine interface Human-machine interface multi-modality (Autonomous network  network operator domain experts) To cater for increased customer diversity and the ongoing trend in application mobilization the autonomous network HMI shall cater for different usage and modes of interaction. The traditional telco big screen model of network operations is not a suitable HMI for many enterprises, and majority of CSPs are mobilizing many of their systems. Where it makes practical sense mobile and AI assistants, or conversational agents shall be available for some applications and use cases. The challenge is to support bidirectional transparency in real time, while not overwhelming the human with too much information and burden 23 Human machine interface Human-machine interface  human-agent teaming The AN HMI shall support flexible modes of human-agent teaming, whereby a human (or group of humans) and the network behave as equal partners on a team (but human intervention is still in place, obviously), and collaborate on goals where there is shared situation awareness within the team. Shared situation awareness is knowledge about the current state of the task environment, as well as team activities, team performance, and overall progression with respect to the team task. Such knowledge shall facilitate coordination and reallocation of tasks within the team but shall also be used for effective and efficient communication among the team members. 24 Human machine interface Human-machine interface presentation of information To eventually reach level 4 and 5 autonomous levels the HMI of the AN should generally only display information for which a human consultation (or decision) is necessary. Presentation of unnecessary information for the task at hand should be avoided as much as possible to avoid overwhelming the human and negatively impact decision making. Note: this may not be achievable from the outset, but it should be a goal, and there should be a plan on how to achieve it 25 Human machine interface

# Background: In today’s network operations many things do not happen

because humans fail to do them, due to other work, absence, or some other reason. For example: the organizations priorities were incorrect because John was out sick this morning - he did not login and run the Wireless status report. All human bottleneck tasks should be found and delegated to the ANs, and the workflow/process redesigned to ensure human bottlenecks are entirely removed. Vendor product offerings should be evaluated on how many (or few) human bottlenecks their products introduce. IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 42 of 43  Category Principle 26 Human machine interface Flight simulator mode As the ANs gets increasingly automated there will be less work for the user to do (in terms of traditional tasks at least). On a similar vein some parts of the network are increasingly reliable, and many error scenarios are not seen regularly, if ever (i. e. extremely rare). The result of these situations is that humans could become deskilled over time because they are not actively doing the work as they did in the past. The AN should support flight simulator style drills in a sandbox or simulation environment to help them maintain their skills and prepare for chaos monkey scenarios that would not normally be experienced. 27 Human machine interface User profiles to better optimize human: machine collaboration To account for the fact that, just like the network, humans change over time (skills, abilities, etc. ) and better enable human collaboration the AN should build targeted profiles of users to understand their technical and operational competences, abilities, and strengths. Such profiles are useful for task/work allocation, ad hoc team formation, user behavioral analysis (to build strong machine learning models, for example), and bias detection. 28 Human machine interface Transformation of product documentation into digital knowledge assets Humans shall not need to refer to individual product documentation for daily network operations, the AN should inform them what they need to know in any given context Product documentation concerning features, capabilities, and dependencies shall be manifested as machine readable artifacts for use by the autonomous, which shall actively use them as knowledge assets. Documentation concerning differences between network function product versions (software and hardware) shall be manifested as machine readable artifacts in order for use by the autonomous network to actively use these facts as knowledge assets, removing painstaking and error prone investigation tasks from humans Traditional network node product documentation shall still have a role for network planners and technical staff involved in procurement evaluation processes. Figure 11 Guiding principles detailed IG1229 Guiding Principles for building and measuring Autonomous Network solutions  TM Forum 2020. All Rights Reserved. Page 43 of 43 14 Appendix II: Map of Guiding Principles Figure 12 Guiding Principles Table 2 Guiding Principles Quick Reference

